org/apache/lucene/analysis/standard/StandardAnalyzer.<init>: 0.0
org/apache/lucene/analysis/standard/StandardTokenizer.next: 0.0
org/apache/lucene/analysis/LowerCaseFilter.<init>: 0.0
org/apache/lucene/analysis/standard/StandardAnalyzer.reusableTokenStream: 0.0
org/apache/lucene/analysis/CharArraySet.getHashCode: 0.03805637830167429
org/apache/lucene/analysis/StopFilter.makeStopSet: 0.0
org/apache/lucene/analysis/standard/StandardTokenizerImpl.<init>: 0.0
org/apache/lucene/analysis/standard/StandardTokenizerImpl.zzUnpackRowMap: 0.0
org/apache/lucene/analysis/LowerCaseFilter.next: 0.0
org/apache/lucene/analysis/standard/StandardTokenizer.class$: 0.0
org/apache/lucene/analysis/LowerCaseFilter.class$: 0.0
org/apache/lucene/analysis/Token.class$: 0.0
org/apache/lucene/analysis/standard/StandardTokenizerImpl.zzUnpackCMap: 0.0
org/apache/lucene/analysis/CharArraySet.getSlot: -0.0014429813490302226
org/apache/lucene/analysis/standard/StandardTokenizer.setMaxTokenLength: 0.0
org/apache/lucene/analysis/StopFilter.next: 0.0
org/apache/lucene/analysis/CharArraySet.equals: -0.02770466761011914
org/apache/lucene/analysis/standard/StandardTokenizerImpl.zzUnpackAction: 0.0
org/apache/lucene/analysis/standard/StandardTokenizerImpl.getText: 0.0
org/apache/lucene/analysis/CharArraySet.<init>: 0.0
org/apache/lucene/analysis/standard/StandardTokenizerImpl.yyreset: 0.0
org/apache/lucene/analysis/Token.setEndOffset: -0.0011240527924197435
org/apache/lucene/analysis/Token.setTermLength: -0.002892869975973206
org/apache/lucene/analysis/standard/StandardFilter.class$: 0.0
org/apache/lucene/analysis/StopFilter.class$: 0.0
org/apache/lucene/analysis/Token.setType: -6.597796513516171E-5
org/apache/lucene/analysis/standard/StandardTokenizerImpl.zzUnpackTrans: 0.0
org/apache/lucene/analysis/Token.setStartOffset: -0.002183197636858234
org/apache/lucene/analysis/standard/StandardFilter.<init>: 0.0
org/apache/lucene/analysis/Token.setPositionIncrement: 0.0
org/apache/lucene/analysis/Token.growTermBuffer: 0.003843926490330036
org/apache/lucene/analysis/standard/StandardTokenizer.reset: 0.0
org/apache/lucene/analysis/Analyzer.setPreviousTokenStream: 0.0
org/apache/lucene/analysis/standard/StandardTokenizer.setReplaceInvalidAcronym: 0.0
org/apache/lucene/analysis/TokenFilter.<init>: 0.0
org/apache/lucene/analysis/Token.reinit: -0.1880130616980076
org/apache/lucene/analysis/Token.setTermBuffer: 0.001204233063577546
org/apache/lucene/analysis/standard/StandardTokenizer.<init>: 0.0
org/apache/lucene/analysis/CharArraySet.contains: -9.157206004465334E-4
org/apache/lucene/analysis/TokenStream.class$: 0.0
org/apache/lucene/analysis/standard/StandardFilter.next: 0.0
org/apache/lucene/analysis/StopFilter.<init>: 0.0
org/apache/lucene/analysis/standard/StandardTokenizerImpl.zzUnpackAttribute: 0.0
org/apache/lucene/analysis/CharArraySet.add: -0.14748465044863146
